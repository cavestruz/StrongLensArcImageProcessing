\documentclass{emulateapj}
\usepackage{amsmath} 
\usepackage{apjfonts} 
\usepackage{amssymb} 
\usepackage{xspace}
\usepackage{hyperref} 
\usepackage{natbib} 
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{epsf}
\usepackage{subfigure}
\bibliographystyle{apj_ads}
\usepackage[usenames,dvipsnames]{xcolor}
\newcommand{\comment}[1]{{\color{red} #1}}
\newcommand{\change}[1]{{\color{blue} #1}}
\newcommand{\todo}[1]{{\bf\color{blue} #1}}
%%%%%%%%%% User defined symbol %%%%%%
\def\gsim{\gtrsim}
\def\lsim{\lesssim}    
\def\Msun{M_\odot}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document} 
\shorttitle{LensFinder}
\shortauthors{Avestruz, Li, Lightman}
\submitted{The Astrophysical Journal} 
\slugcomment{The Astrophysical Journal, submitted}

\title{MachLLensFinder - I: A Machine Learning Strong Lensing
  Identification Pipeline}

\author{Camille Avestruz\altaffilmark{1-3}\thanks{E-mail:
    avestruz@uchicago.edu}, Nan Li\altaffilmark{2,3,4}, and Matthew Lightman\altaffilmark{5} }

\affil{
$^1${Enrico Fermi Institute, The University of Chicago, Chicago, IL 60637 U.S.A.}\\
$^2${Kavli Institute for Cosmological Physics, The University of Chicago, Chicago, IL 60637 U.S.A.}\\
$^3${Department of Astronomy \& Astrophysics, The University of Chicago, Chicago, IL 60637 U.S.A.};
  \href{mailto:avestruz@uchicago.edu}{avestruz@uchicago.edu}\\
}

\keywords{gravitational lensing --- methods : numerical --- methods: data analysis --- methods: statistical --- galaxies: elliptical --- surveys  }
  
%-------------------------------------------------%
\begin{abstract} 
  Gravitational lensing offers a direct probe of the underlying mass
  distribution of lensing systems, a window to the high redshift
  universe, and a geometric probe of cosmological models.  The advent
  of large scale surveys such as LSST and Euclid has prompted a need
  for automatic and efficient identification of strong lensing
  systems.  In this first paper of a series, we present LensFinderML,
  a strong lensing identification pipeline that will be publicly
  released as open source software.

Giant arcs trace... cosmology... mass distribution.  Advent of DES,
LSST, etc. need an efficient way to identify strong lens images.  We
present {\sc{MACHLLENSFINDER}} (MACHine Learning LENSFINDER), an open source
image processing and deep learning.  This first paper focuses on image
Processing Techniques for Giant Arc Identification Tests with mock
images from ... ...  Image processing improves by....
\end{abstract}
%-------------------------------------------------%

%-------------------------------------------------%
\section{Introduction}
%-------------------------------------------------%

% Gravitational lensing as a geometric (?) test of cosmology.  Also
% probes underlying matter distribution in galaxy clusters, sensitive
% to things like recent accretion and environment.
Gravitational lensing deflections due to gravity... \citep[see][for a
  review]{kneibandnatarajan_11}.  Strong lensing visible ... giant
arcs, multiple images, and arclets.  Galaxy clusters as strong lens,
deep gravitational potential well, can see by eye.  Strong lensing
signatures probe underlying dark matter distribution of galaxy
clusters, magnify the background galaxy population allowing us to
probe formation at epochs further back in time, and geometric test of
cosmology.

% Arc identification can be done visually (e.g. that zooniverse
% thing).  But, in the advent of optical surveys, DES and LSST, we
% will be limited by our ability to automatically process the large
% amounts of data.  Wide field surveys - SPT in millimeter, Herschel
% in submillimeter; high resolution spectroscopic imaging with ALMA;
% optical surveys DES, HSC, LSST, and Euclid (Oguri \& Marshall 2010).
The geometric test of cosmology requires a comparison of predicted arc
abundances and observed abundances.  In the advent of large surveys,
such as DES and LSST, we will be limited by our ability to
automatically process the large amounts of data and select likely
strong lensing clusters for follow up spectroscopic measurements to
positively identify background galaxy images.  Image identification
has had an onslaught of new works (wc).

% Serentipitous discoveries confirmed the theory (cite Einstein)
% Cite first discoveries of different shapes of strong lensing images
% While some serendipitous systems found recently (gladders+),
% Describe the uptick in amount of data
% End with need to scale with the volume of data
Early strong lensing images were serendipitous discoveries
(e.g. multiple quasars \citep{walsh_etal79}, arcs in clusters
\citep{lyndsandpetrosian_86}, ...).  As the number of images with
potential lensing systems increased, infrastructure emerged for both
automated and visual inspection.  

% Image identification works: visual, ``robot'' identification -
% ArcFinder, RingFinder..., and citizen science (space warps).
% Many of these rely on some explicit aspect of the image's morphology (give example), filtering, ... ....
% Specifics of the methodology how the instrument affects the strong lensing signal, and the objects of interest.

Automated lensed image identification has fallen under the term
``robot'' identification, where images are fed into some kind of image
processing pipeline that enhances and extracts characteristic features
as parameters that are fed into some kind of cutoff or pattern
recognition piece.  ArcFinder
... .... \citep{seidelandbartelmann_07}. For multiply imaged quasars,
Ringfinder ... ... ...\citep{gavazzi_etal14}.  Each pipeline
.... ... and relies on the image morphology where ... ...  Note, that
the method best applied to ... ... and the objects of interest.  The
human eye is one of the best discriminators of.... SpaceWarps is an
example of citizen science... visual identification
\citep{marshall_etal16,more_etal16}.  However, scalability, training
....

% Arc finding must optimize for completeness and purity.  Completeness
% (no false negatives), purity (minimal false positives).  Purity can
% be double checked in a smaller subsample of the data visually.  And,
% spectroscopic follow up is expensive.  Also, scalability of the
% strong lens finding method matters - example with the citizen
% science.
In general, lensed image finding must optimize for completeness and
purity.  In the application of arc abundance comparisons with
cosmological predictions, completeness is important; we must be able
to understand the reasons and frequency of false negatives.  Since
spectroscopic confirmation of background lensed images is expensive,
purity is key; we must minimize false positives that would waste
follow up telescope time.

% Machine learning to automate.  Previous works (StrongML),
% More+... Here, we focus on the improvement from preprocessing the
% images and describe the pipeline, which is publicly available.
% Depending on the image type, different preprocessing is likely
% necessary (rings, multiply lensed quasars, etc.) Our goal is to
% create an open source pipeline that is general enough for the user
% to select or add appropriate image processing techniques to augment
% the features of the lensed image, train and test data with different
% machine learning techniques, and to select the sequence of methods
% that maximizes completeness with optimal purity.


% No need to explicitly extract morphological parameters to a pattern
% finding, simply transform the image according to the appropriate
% image preprocessing function, and directly feed this into the
% machine learning ... 

% This is the first in a series of LensFinder papers where we present
% our initial pipeline results with a test... of .... Image
% preprocessing.... same technology to validate watermarks


Our paper is organized as follows.  In Section~\ref{sec:methods} we
briefly describe ...  We present our results in
Section~\ref{sec:results}, and our summary and discussions in
Section~\ref{sec:conclusions}.

%-------------------------------------------------%
\section{Methodology}
\label{sec:methods}
%-------------------------------------------------%

%-------------------------------------------------%
\subsection{Image Processing Pipeline}
%-------------------------------------------------%

**Results of Grid search across the parameters of the pipeline**

%-------------------------------------------------%
\subsubsection{Histogram Oriented Gradients}
%-------------------------------------------------%
Histogram oriented gradients (HOG) is a feature extraction method that
computes centered horizontal and vertical gradients with no smoothing.
Originally created for human detection, .... This computes the
gradient orientation and magnitudes in an image by first dividing the
image into $n\times n$ blocks of X\% overlap.  The gradient
orientation is then quantized into m bins. ``(optional) global image
normalisation computing the gradient image in x and y computing
gradient histograms normalising across blocks flattening into a
feature vector''\citep{dalalandtriggs_05}.

% Need to look into edge orientation histograms, scale-invariant
% feature transform descriptors, shape contexts.


% NEED TO FEED THE DESCRIPTORS TO SOMETHING WITH SUPERVISED LEARNING.
% (e.g. SVM, Neural network).

%-------------------------------------------------%
\subsection{Logistic Regression}
%-------------------------------------------------%


% Regularization coefficient:
% http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&doc=exercises/ex5/ex5.html


%-------------------------------------------------%
\subsection{Deep Learning Algorithm}
%-------------------------------------------------%

%-------------------------------------------------%
\subsection{Mock Test Images}
%-------------------------------------------------%


%-------------------------------------------------%
\section{Results}
\label{sec:results}
%-------------------------------------------------%
%-------------------------------------------------%
\subsection{Optimized pipeline parameters}
%-------------------------------------------------%

\begin{table}
\caption{Grid Search of Pipeline Parameters}
\begin{center}
\begin{tabular}{cccccc}
\hline \\ [-0.2cm]
N$_{orient}$ & Pixels/Cell & Cells/Block & LogReg$_{\text{coeff}}$ & HOG size & Score \\ [0.2cm]
\hline \\ [-0.2cm]
\multicolumn{6}{c}{(a) HST-like data} \\ [0.2cm]
\hline \\ [-0.2cm]
9 & (4, 4) & (3, 3) & 50. & &$0.76181\pm0.00491$\\ [0.2cm]
9 & (4, 4) & (1, 1) & 50. & &$0.83403\pm0.00547$\\ [0.2cm]
9 & (8, 8) & (3, 3) & 50. & &$0.85417\pm0.00851$\\ [0.2cm] 
9 & (8, 8) & (1, 1) & 50. & &$0.86389\pm0.00687$\\ [0.2cm] 
9 & (16, 16) & (1, 1) & 50. & & $0.88542\pm0.00680$ \\ [0.2cm]
9 & (16, 16) & (3, 3) & 10. & &$0.89306\pm0.00687$ \\ [0.2cm]
8 & (16, 16) & (3, 3) & 50. & &$0.90000\pm0.00170$ \\ [0.2cm]
9 & (16, 16) & (3, 3) & 50. & &$0.90139\pm0.00804$ \\ [0.2cm]
\hline \\ [-0.2cm]
\multicolumn{6}{c}{(b) LSST-like data} \\ [0.2cm]
\hline \\ [-0.2cm]
& & & & &\\
& & & & &\\ [0.2cm]
\hline
\end{tabular}
\end{center}
\label{tab:gridsearch}
\tablecomments{Panel (a) shows the results of a grid search across a
  range of HOG parameters and regression coefficient with training and
  test sets of size 1440 with the HST-like mock dataset.  Panel (b)
  shows the corresponding results for training and test sets of size
  5760 with the LSST mock dataset.  We explore different HOG
  parameters in each dataset due to resolution and image size
  differences.}
\end{table}

We run a grid search across parameters that should reasonably sample
the arc edges in either the HST- or LSST-like mock observations.
Recall, the HST-like images are $300\times300$ pixels per image, while
the LSST-like mock observations are $45\times45$ pixels per image.  In
general, must run a grid search in order to best optimize the pipeline
parameters.

We must first estimate the size of a cell that will contain a coherent
arc feature.  To first order approximation, subdivisions of cells that
are 1/100th the area of the entire image should contain coherent arc
edges that span an elongated shape within arc-containing cells.
Therefore, we perturb the pixels per cell parameter about (30, 30) for
the HST-like images, and (4, 4) for the LSST-like images.

Next, the cells per block parameter determines the normalization of
each cell with respect to the neighboring cell.  In general, this will
downweight arc-like edges in cells that neighbor very bright cells,
such as cells that cover the BCG.  We therefore vary the cells per
block parameter between (1, 1) and (3, 3).

The number of orientations will determine the sampling of rounded
edges.  For example, if we only have two orientations, an arc-like
feature in a cell will appear as .... However, contributions from a
cluster or line-of-sight galaxy in the same cell will ... the
normalizations in the histogram.  The resolution of the overall image
will also limit the additional information that an increase in
$N_\text{orientations}$ will provide.  For the LSST-like data,
$N_\text{orientations}=9$ compared with $N_\text{orientations}=5$ only
results in a $???\%$ improvement.  In the case of the HST-like data,
$N_\text{orientations}=9$ compared with $N_\text{orientations}=5$
results in a $???\%$ improvement.

Note, we also include the size of the extracted features, e.g. the
length of the HOG.  Larger features will increase the amount of time
required to train a model, and also impact memory restrictions on the
size of the training set.  The logistic regression coefficient will
also increase the training time.  We discuss the score dependence on
logistic regression coefficient in Section\ref{sec:unregularizedfit}.


\subsection{Scores vs. regularization on larger train/test set with comparable grid search in parameterization}\label{sec:unregularizedfit}

\subsection{False positives/negatives and why... something about likely images given cosmology}

\subsection{ROC curve}

\subsection{Effects of BCG contamination}

%-------------------------------------------------%
\section{Summary and Discussions}
\label{sec:conclusions}
%-------------------------------------------------%

We summarize key points below:

%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}

\item 
    
\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%

These results indicate that...

\acknowledgments CA acknowledges support from the Kavli Institute of
Cosmological Physics, the Enrico Fermi Institute at the University of
Chicago, and the University of Chicago Provost's Office.
\lastpagefootnotes


\bibliography{ms}

\end{document}  

